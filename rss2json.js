const rss2json = {"Scitech": {"https://newatlas.com/science/index.rss": {"feed": {"title": "Science"}, "entries": []}, "https://www.cbsnews.com/latest/rss/science": {"feed": {"title": "Science - CBSNews.com"}, "entries": []}, "https://www.cbsnews.com/latest/rss/space": {"feed": {"title": "Space - CBSNews.com"}, "entries": []}}, "Gadgets": {"https://www.emergentmind.com/feeds/rss": {"feed": {"title": "Emergent Mind Feed"}, "entries": []}}, "Food_Health": {"https://phys.org/rss-feed/biology-news/agriculture/": {"feed": {"title": "Agriculture news"}, "entries": []}}, "Nature": {"http://feeds.feedburner.com/DiscoverLivingWorld": {"feed": {"title": "Planet Earth | Discover Magazine"}, "entries": [{"title": "Bat Tolerance to Viral Infections Could Help Humans Become More Resilient, Too", "summary": "Discover how learning more about how bats harbor viruses and infections without becoming ill could help keep humans healthy, too.", "link": "https://www.discovermagazine.com/planet-earth/bat-tolerance-to-viral-infections-could-help-humans-become-more-resilient", "published_js": "2025-05-17", "author": "Avery Hurt"}]}, "http://feeds.feedburner.com/DiscoverEnvironment": {"feed": {"title": "Environment | Discover Magazine"}, "entries": []}}, "Business": {}, "Foss_Self-hosting": {}, "History": {}, "News": {"https://www.livemint.com/rss/politics/": {"feed": {"title": "mint - politics"}, "entries": [{"title": "Meloni Says She\u2019s No Shrink to Global Leaders as She Meets Merz", "summary": "Italian Premier Giorgia Meloni said she isn\u2019t a \u201cshrink to international leaders\u201d after she was asked to give advice to German Chancellor Friedrich Merz for his upcoming trip to meet US President Donald Trump.", "link": "https://www.livemint.com/politics/news/meloni-says-she-s-no-shrink-to-global-leaders-as-she-meets-merz-11747510108094.html", "published_js": "2025-05-17", "author": "None"}, {"title": "Setback for Arvind Kejriwal: 13 AAP councillors in Delhi leave party to float new outfit. Know why", "summary": "While Mukesh Goyal will serve as the president of the Indraprastha Vikas Party, veteran municipal figure Hemchand Goyal will lead the outfit.", "link": "https://www.livemint.com/politics/setback-for-arvind-kejriwal-13-aap-councillors-in-delhi-leave-party-to-float-new-outfit-know-why-11747486534249.html", "published_js": "2025-05-17", "author": "None"}, {"title": "'Informing Pakistan at start of attack was crime': Rahul Gandhi on Jaishankar's remark on Operation Sindoor", "summary": "In a post on X, Gandhi questioned External Affairs Minister (EAM) S Jaishankar for publicly admitting that the government of India (GOI) had informed Pakistan of the action and asked how many aircraft the Indian Air Force lost as a result.", "link": "https://www.livemint.com/politics/informing-pakistan-at-start-of-attack-was-crime-rahul-gandhi-on-jaishankars-remark-on-operation-sindoor-11747483593702.html", "published_js": "2025-05-17", "author": "None"}, {"title": "Shehbaz Sharif \u2018pakde gaye\u2019: Pakistani influencer exposes Pakistan PM's blatant lies about India", "summary": "Pakistani influencer Waqar Malik criticised Prime Minister Shehbaz Sharif and questioned the logic behind India's attack after a ceasefire was supposedly agreed upon.", "link": "https://www.livemint.com/politics/news/shehbaz-sharif-pakde-gaye-pakistani-influencer-exposes-pakistan-pms-blatant-lies-on-india-11747478344744.html", "published_js": "2025-05-17", "author": "None"}, {"title": "'Cannot include names without...': Shashi Tharoor's name in global outreach delegation sparks BJP vs Congress slugfest", "summary": "The Centre recently named Shashi Tharoor as the leader of the US delegation that will be part of the diplomatic outreach programme over the April 22 Pahalgam terror attack and India's subsequent retaliation againt terror camps located in Pakistan, named Operation Sindoor.", "link": "https://www.livemint.com/politics/cannot-include-names-without-shashi-tharoors-name-in-global-outreach-delegation-sparks-bjp-vs-congress-slugfest-11747472837120.html", "published_js": "2025-05-17", "author": "None"}, {"title": "\u2018When national interest is\u2026\u2019: Shashi Tharoor to lead all-party delegations to brief nations after Operation Sindoor", "summary": "Shashi Tharoor expressed honor in leading an all-party delegation representing India at key global capitals. The delegation aims to convey a unified message against terrorism, following Operation Sindoor.", "link": "https://www.livemint.com/politics/news/when-national-interest-is-shashi-tharoor-to-lead-all-party-delegations-to-brief-nations-after-operation-sindoor-11747461097002.html", "published_js": "2025-05-17", "author": "None"}]}, "https://www.livemint.com/rss/industry": {"feed": {"title": "mint - industry"}, "entries": [{"title": "Bank holidays this week: Is the coming Saturday a weekend off? Check full schedule here", "summary": "Bank holidays this week: Is the coming Saturday, May 24, a weekend off? Check full schedule here for May 18-25 next week.", "link": "https://www.livemint.com/industry/banking/bank-holidays-this-week-fourth-saturday-may-24-weekend-off-check-full-schedule-here-may-18-to-may-25-sunday-rbi-sbi-news-11747533834440.html", "published_js": "2025-05-18", "author": "None"}]}, "swarajyamag.com": {"feed": {"title": "swarajyamag.com"}, "entries": []}}, "Reddit": {"https://oauth.reddit.com/r/todayilearned/top": {"feed": {"title": "Reddit - TIL"}, "entries": [{"title": "TIL Hulk Hogan claimed in his autobiography that he once wrestled 400 days in a year because of his frequent trips back and forth from the USA and Japan", "summary": "", "link": "https://itrwrestling.com/news/hulk-hogans-bizarre-claim-of-wrestling-over-400-days-a-year/", "author": "None"}, {"title": "TIL two prison escapees from Utah were arrested by UC Berkeley police officers after they claimed to be from San Francisco by saying \"I'm from Frisco\", which aroused the officers' suspicions because \"no one from here ever says that.\"", "summary": "", "link": "https://www.sfgate.com/news/article/frisco-you-re-under-arrest-3132594.php", "author": "None"}, {"title": "TIL in the late 1960s George Carlin made about $250K annually, however in 1970 he changed his routines &amp; his appearance. He grew his hair long, sported a beard, &amp; wore earrings to look more \"hip\" for a younger audience. After his income declined by 90% initially, his career arc was greatly improved.", "summary": "", "link": "https://en.wikipedia.org/wiki/George_Carlin#:~:text=1970%E2%80%931971%3A%20Transformation%5B,improved.%5B37%5D", "author": "None"}, {"title": "TIL one night at a craps table in Las Vegas in 1980s Elvis Presley's manager Colonel Tom Parker said \"Let me rub your head for luck, boy\" to Eddie Murphy before rubbing his head. Murphy wanted to punch him in the face, but said the 80-year-old Parker was \"too old to be taught the limits of racism.\"", "summary": "", "link": "https://faroutmagazine.co.uk/colonel-tom-parker-crossed-line-eddie-murphy/", "author": "None"}, {"title": "TIL Zlatan Ibrahimovic played with a torn ACL for 6 months at age 40 so he could win one final trophy, and managed to score 8 goals while on painkillers and injections.", "summary": "", "link": "https://www.bbc.com/sport/football/61583823", "author": "None"}, {"title": "TIL the on set feud between Wesley Snipes &amp; director David S. Goyer while filming Blade: Trinity led to Snipes only appearing on set to film close-ups (often completely stoned) &amp; letting his double shoot most of his scenes. And he only communicated with Goyer via Post-it notes, signing them as Blade", "summary": "", "link": "https://www.slashfilm.com/733618/wesley-snipes-famously-refused-to-film-most-of-his-blade-trinity-scenes/", "author": "None"}, {"title": "TIL That an Irish woman attempted to murder Italian Fascist dictator Benito Mussolini in 1926, armed with a revolver, she aimed at Mussolini's head but a sudden head movement saved him at the last second, with the bullet only managing to wound his nose.", "summary": "", "link": "https://en.wikipedia.org/wiki/Violet_Gibson", "author": "None"}, {"title": "TIL in Rocky (1976), when the fight poster shows Rocky in the wrong color shorts, that was not intentional. The art department messed up, showing red with a white stripe instead of white with a red stripe. The budget was only around a million dollars, so they had Rocky point it out in the film.", "summary": "", "link": "https://www.slashfilm.com/1180014/how-rocky-turned-an-art-department-mishap-into-a-moment-of-sympathy/", "author": "None"}, {"title": "TIL that 75% of the world\u2019s food is generated from only 12 plants and 5 animal species.", "summary": "", "link": "https://thefuturemarket.com/biodiversity", "author": "None"}, {"title": "TIL about Fat Club, men's organizations that were  popular in the late 19th and early 20th century . The 1st rule of Fat Club was, you had to be at least 200 pounds to join.", "summary": "", "link": "https://www.npr.org/sections/thesalt/2016/03/07/469571114/the-forgotten-history-of-fat-men-s-clubs", "author": "None"}, {"title": "TIL all of Jimmy Carter's siblings and father died from pancreatic cancer", "summary": "", "link": "https://www.cbsnews.com/news/family-history-of-cancer-eyed-in-jimmy-carter-diagnosis/", "author": "None"}, {"title": "TIL that in 2011 during a primary debate, candidate Rick Perry tried to name three federal departments he wanted to eliminate but forgot the Department of Energy and ended with \"Oops.\" The moment is widely blamed for damaging his campaign. In 2017, he was confirmed Secretary of Energy.", "summary": "", "link": "https://en.wikipedia.org/wiki/Rick_Perry", "author": "None"}, {"title": "TIL in the early 20th century, in order to prevent smells and occasional explosions, the United Kingdom installed \"Sewer Gas Destructor Lamps.\" The street lamps, connected to sewer vents, generated heat which would draw up gases to the lanterns. The odors and bacteria would burn off in the flames.", "summary": "", "link": "https://www.bbc.com/news/uk-england-south-yorkshire-39409984", "author": "None"}, {"title": "TIL Macho Man Randy Savage first began wrestling professionally while still playing pro baseball, moonlighting as a masked wrestler named \"The Spider\".", "summary": "", "link": "https://en.wikipedia.org/wiki/Randy_Savage#Professional_wrestling_career", "author": "None"}, {"title": "TIL that during the sinking of the USS Lexington in 1942 after Japanese attacks, sailors paused evacuating to get ice cream to take with them before jumping ship", "summary": "", "link": "https://www.usni.org/magazines/naval-history-magazine/2022/august/sailors-scream-ice-cream", "author": "None"}, {"title": "TIL that between 1996 and 2000, Peru\u2019s government forcibly sterilised around 300,000 mostly Indigenous women under a population control program\u2014many without informed consent or medical justification.", "summary": "", "link": "https://en.wikipedia.org/wiki/Forced_sterilization_in_Peru", "author": "None"}, {"title": "TIL In 2005 a man named Dean Karnazes ran 350 miles with zero sleep. He ran for 80 hours and 44 minutes straight.", "summary": "", "link": "http://www.atrailrunnersblog.com/2005/10/dean-karnazes-talks-about-his-350-mile.html?m=1", "author": "None"}, {"title": "TIL in October 1918, Alvin York, under German fire, took command after his unit was pinned down. Using expert marksmanship, he killed around 20 enemies and captured 132 more, silencing multiple machine guns and earning the Medal of Honor for his bravery", "summary": "", "link": "https://en.wikipedia.org/wiki/Alvin_York", "author": "None"}, {"title": "TIL Benito Mussolini was fascinated by reports of homosexual activity among senior Catholic clerics at the Vatican and ordered the Italian secret police to send those reports to his office", "summary": "", "link": "https://en.wikipedia.org/wiki/OVRA", "author": "None"}, {"title": "TIL Much of the northern US wanted to go to war with Great Britain again in 1837, after an American-donated ship for a minor rebellion in Canada was seized in US territory, set on fire, and sent down Niagara Falls, to which some Americans burnt a British steamer in response.", "summary": "", "link": "https://en.wikipedia.org/wiki/Caroline_affair", "author": "None"}, {"title": "TIL that during the Battle of Trafalgar, only one ship was destroyed (the Achille on the Franco-Spanish side) through direct combat via a fire that reached the magazine, causing an explosion. While the British were able to capture 17 enemy ships without losing any of their ships during the battle.", "summary": "", "link": "https://www.rmg.co.uk/stories/topics/battle-of-trafalgar", "author": "None"}, {"title": "TIL that Hachik\u014d, the dog who continued visiting the train station daily for over nine years after his owner's death, had four yakitori skewers in his stomach when he died. They neither harmed his stomach nor led to his death. He died of terminal cancer and worms.", "summary": "", "link": "https://wikipedia.org/wiki/Hachik%C5%8D#:~:text=Hachik%C5%8D%20", "author": "None"}, {"title": "TIL that Waffle House has its own record company called Waffle House records, that releases cd\u2019s and vinyl\u2019s of their jukebox hits", "summary": "", "link": "https://boingboing.net/2022/07/07/waffle-house-has-its-own-record-label-and-the-songs-are-in-the-restaurant-jukeboxes.html/amp", "author": "None"}, {"title": "TIL that the Japanese word for wisdom teeth literally means \"unknown to parents\" because wisdom teeth generally erupt long after a person has gained independence and left their childhood home.", "summary": "", "link": "https://www.bionity.com/en/encyclopedia/Wisdom_teeth.html#Etymology", "author": "None"}, {"title": "TIL that on the eve of the civil war 44% of florida\u2019s population was made up of enslaved people", "summary": "", "link": "https://floridahumanities.org/blog/floridas-culture-of-slavery/", "author": "None"}]}, "https://oauth.reddit.com/.json": {"feed": {"title": "Reddit - TIL"}, "entries": [{"title": "Multi-Source RAG with Hybrid Search and Re-ranking in OpenWebUI - Step-by-Step Guide", "summary": " Hi guys, I created a DETAILED step-by-step hybrid RAG implementation guide for OpenWebUI -\n\n[\n\nLet me know what you think.  I couldn't find any other online sources that are as detailed as what I put together.  I even managed to include external re-ranking steps which was a feature just added a couple weeks ago.    \nI've seen people ask questions about how to set up RAG in OpenWebUI for a while so wanted to contribute.  Hope it helps some folks out there!", "link": "https://www.reddit.com/r/OpenWebUI/comments/1kp5spy/multisource_rag_with_hybrid_search_and_reranking/", "author": "None"}, {"title": "Ollama multimodal engine release", "summary": "With Ollama\u2019s multimodal engine release my assumption is that OUI will support Ollama\u2019s multimodal engine without any OUI configuration changes; i.e. \u2018out of the box\u2019. True | False?\n\n", "link": "https://www.reddit.com/r/OpenWebUI/comments/1kox16z/ollama_multimodal_engine_release/", "author": "None"}, {"title": "Why I don't like role prompts.", "summary": "There, I said it. I don't like role prompts. Not in the way you think, but in the way that it's been over simplified and overused. \n\nWhat do I mean? Look at all the prompts nowadays. It's always \"You are an expert xxx.\", \"you are the Oracle of Omaha.\" Does anyone using such roles even understand the purpose and how assigning roles shape and affect the LLM's evaluation? \n\nLLM, at the risk of oversimplification, are probabilistic machines. They are NOT experts. Assigning roles doesn't make them experts. \n\nAnd the biggest problem i have, is that by applying roles, the LLM portrays itself as an expert. It then activates and prioritized tokens. But these are only due to probabilities. LLMs do not inherently an expert just because it sounds like an expert. It's like kids playing King, and the king proclaims he knows what's best because he's the king.\n\nA big issue using role prompts is that you don't know the training set. There could be insufficient data for the expected role in the training data set. What happens is that the LLM will extrapolate from what it thinks it knows about the role, and may not align with your expectations. Then it'll convincingly tell you that it knows best. Thus leading to hallucinations such as fabricated contents or expert opinions.\n\nDon't get me wrong. I fully understand and appreciate the usefulness of role prompts. But it isn't a magical bandaid. Sometimes, role prompts are sufficient and useful, but you must know when to apply it. \n\nBreaking the purpose of role prompts, it does two main things. First, domain. Second, output style/tone.\n\nFor example, if you tell LLM to be Warren Buffett, think about what do you really want to achieve. Do you care about the output tone/style? You are most likely interested in stock markets and especially in predicting the stock markets (sidenote: LLMs are not stock market AI tools).\n\nIt would actually be better if your prompt says \"following the theories and practices in stock market investment\". This will guide the LLM to focus on stock market tokens (putting it loosely) than trying to emulate Warren Buffett speech and mannerisms. And you can go further to say \"based on technical analysis\". This way, you have fine grained access over how to instruct the domain. \n\nOn the flip side, if you tell LLM \"you are a university professor, explain algebra to a preschooler\". What you are trying to achieve is to control the output style/tone. The domain is implicitly define by \"algebra\", that's mathematics. In this case, the \"university lecturer\" role isn't very helpful. Why? Because it isn't defined clearly. What kind of professor? Professor of humanities? The role is simply too generic. \n\nSo, wouldn't it be easier to say \"explain algebra to a preschooler\"? The role isn't necessary. But you controlled the output. And again, you can have time grain control over the output style and tone. You can go further to say, \"for a student who haven't grasped mathematical concepts yet\".\n\nI'm not saying there's no use for role prompts. For example, \"you are jaskier, sing praises of chatgpt\". Have fun, roll with it \n\nUltimately, my point is, think about how you are using role prompts. Yes it's useful but you don't have fine control. It's better actually think about what you want. For role prompts, you can use it as a high level cue, but do back it up with details. ", "link": "https://www.reddit.com/r/PromptEngineering/comments/1koxgss/why_i_dont_like_role_prompts/", "author": "None"}, {"title": "All Qwen3 uploads updated with fixed chat templates!", "summary": "Thanks to a r/localllama user, they found out there was a bug in Qwen's chat template so, we've now updated all the Qwen3 GGUFs and safetensors with the fixed chat template! Should improve results slightly.\n\nOriginal post for Qwen3 chat template bug findings:\n", "link": "https://huggingface.co/collections/unsloth/qwen3-680edabfb790c8c34a242f95", "author": "None"}, {"title": "Knowing that a response is not \u201canswering\u201d you, is a powerful tool to prompt engineering.", "summary": "# my soapbox\n\nWhen you ask a question to an LLM, the words it writes back are not designed to answer that question. Instead it is designed to predict the next word. The fact that it can somehow accurately answer anything is astounding and basically magic. But I digress\u2026\n\nMy prompting has changed a lot since coming to the understanding that you have full control over the responses. Assume that every response it gives you is a \u201challucination\u201d. This is because it\u2019s not pulling facts from a database, it is just guessing what would be said next. \n\nTo drive the point home, Reddit is an amazing place, but can you trust any given redditor to provide nuanced and valuable info? \n\nNo\u2026\n\nIn fact, it\u2019s rare to see something and think, \u201cwow this is why I come to Reddit\u201d.\n\nLLMs are even worse because they are an amalgam of every redditor that\u2019s ever reddited. Then guessing! Everything an LLM says is a hallucination of essentially the collective unconscious.\n\n# How you can improve your prompting based on the science of how neural networks work.\n\n1. Prime the chat with a vector placement for its attention heads. Because the math can only be done based on text already written by you or it, the LLM needs an anchor to the subject. \n\nExample: I want to know about why I had a dream about my father in law walking in on me pooping, stripping naked, and weighing himself.  But I don\u2019t want it to hallucinate. I want facts. So I can prime the chat by saying \u201ctalk about studies with dreams\u201d. This is simple but it\u2019s undoubtedly in the realm of something the LLM has been trained on. \n\n2. Home in on your reason for prompting. If you start with a generalized token vector field, you can hone in on the exact space you want to be. \n\nExample: I want facts, so I can say something like \u201cWhat do we know for certain about dreams?\u201d\n\n3. Link it to reality. Now we\u2019ve exhausted the model\u2019s training and set the vector space in a factually based manner. But we don\u2019t know if the model has been poisoned. So we need to link it with the internet. \n\nExample: \u201cPrepare to use the internet (1). Go through your last 2 responses and find every factual claim you have made. List them all out in a table. In the second column think about how you could verify each item (2). In the third column use the internet to verify if a claim was factual or not. If you find something not factually based, fix it then continue on.\u201d\n\n(1) - notice how I primed it to let it know specifically that it needed to use the internet.\n(2) - notice how I have it talk about something you want it to do so that it can use that as \u2018logic\u2019 when it actually fact checks.\n\n4. Now you have a good positioning in the field, and your information is at least more likely to be true. Ask your question.\n\nExample: \u201cI\u2019m trying to understand a dream I had. [I put the dream here].\u201d (1)\n\n(1). Notice how I try not to say anything about what it should or shouldn\u2019t do. I just tell it what I want. I want to understand. \n\n# Conclusion\n\nWhen you don\u2019t prune your output, you get the redditor response. When you tell it to \u201cAct as a psychotherapist\u201d, you get a armchair redditor psychoanalytical jargon landscape. But if you give it a little training by having it talk about an idea, you place it in a vector where actual data lives. \n\nYou can do this on one shot, but I like multi shot as it improves fidelity.\n", "link": "https://www.reddit.com/r/PromptEngineering/comments/1kowy9k/knowing_that_a_response_is_not_answering_you_is_a/", "author": "None"}, {"title": "Beyond Diplomacy: Is India Destined to Stand Alone in Times of Conflict?", "summary": "It\u2019s time we Indians take a hard look at who truly stands with us \u2014 and who doesn\u2019t. The recent India-Pakistan standoff brought some uncomfortable realities into focus:\n\n\u2022\tChina: Not only did China back Pakistan diplomatically, it escalated its own confrontation with India by renaming 27 locations in Arunachal Pradesh \u2014 a blatant challenge to our sovereignty.\n\n\u2022\tUnited States: The US stayed carefully neutral, and later, Trump claimed he averted a nuclear war \u2014 taking credit for a ceasefire India didn\u2019t seek mediation for. Soon after, the US urged Apple to reduce its reliance on Indian manufacturing, citing economic and strategic rebalancing.\n\n\u2022\tIsrael: India-Israel relations are often praised as strong and reliable. But even Israel maintained diplomatic silence during the flare-up. No clear statement of support, despite our growing defense and tech ties. \n\n\u2022\tRussia: Once our closest defense ally, Russia is now openly aligning with China. Putin and Xi Jinping marched side by side in Moscow\u2019s Victory Day parade. Not a single statement from Moscow during our standoff with Pakistan.\n\nSo let\u2019s ask:\nWhere are our \u201cstrategic partners\u201d when it counts?\nDeals, summits, and smiles aside \u2014 when we are challenged, do they speak for us? Do they take our side?\n\nStrategic autonomy is valuable. But strategic loneliness is dangerous.\nIt\u2019s time our foreign policy matched the hard realities of global power \u2014 not just its ideals.\n\nLet\u2019s stop mistaking access for alliance \u2014 and start demanding real reciprocity.\n\n", "link": "https://www.reddit.com/r/GeopoliticsIndia/comments/1kou3ep/beyond_diplomacy_is_india_destined_to_stand_alone/", "author": "None"}, {"title": "vscode plugin for version fox?", "summary": "is any Visual Studio Code plugin out there for version fox to handle java/maven/python/etc. by project/workspace?  \n", "link": "https://i.redd.it/mmy9akg29e1f1.png", "author": "None"}, {"title": "Trump just undermined America\u2019s strategic partnership with India", "summary": "", "link": "https://thehill.com/opinion/international/5304742-trump-just-undermined-americas-strategic-partnership-with-india/", "author": "None"}, {"title": "Israel airstrike kills at least 24 in Gaza as mediators host ceasefire talks", "summary": "", "link": "https://www.reuters.com/world/middle-east/israel-airstrike-kills-least-24-gaza-mediators-host-ceasefire-talks-2025-05-17/", "author": "None"}, {"title": "Trump claims India willing to cut \u2018100% of tariffs for United States\u2019", "summary": "", "link": "https://www.thehindu.com/news/international/trump-claims-india-willing-to-cut-100-of-tariffs-for-united-states/article69586437.ece", "author": "None"}, {"title": "President Trump's social media posts ghostwriter?", "summary": "This is not political.  Has anyone noticed there seems to be some distinct differences in President Trump's social media posts recently? From what I can recall, his posts over the past few years have tended to be all capital letters, punctuation optional at best.  Lately, some of the posts put out under his name seem written by a different person.  More cohesive sentences and near perfect punctuation. \n\nIs there any way to use structure or sentiment analysis to see if this is true?  ", "link": "https://www.reddit.com/r/LanguageTechnology/comments/1kp6z11/president_trumps_social_media_posts_ghostwriter/", "author": "None"}, {"title": "Reddit Prompt advice requested.", "summary": "What is your go-to prompt from r/AITAH posts that sound realistic?", "link": "https://www.reddit.com/r/PromptEngineering/comments/1kp3or4/reddit_prompt_advice_requested/", "author": "None"}, {"title": "Israel launches major offensive as Gaza rescuers say scores killed", "summary": "", "link": "https://www.bbc.com/news/articles/cd7geg3lvz1o", "author": "None"}, {"title": "Texas Roadhouse fulfills customer\u2019s special request - his dog\u2019s last meal", "summary": "", "link": "https://www.today.com/today/amp/rcna206850", "author": "None"}, {"title": "Are India-US Relations Entering a Difficult Phase?", "summary": "", "link": "https://thediplomat.com/2025/05/are-india-us-relations-entering-a-difficult-phase/", "author": "None"}, {"title": "India should lower tariffs \u2013 for the right reason", "summary": "", "link": "https://indianexpress.com/article/opinion/editorials/india-should-lower-tariffs-for-the-right-reason-10011367/", "author": "None"}, {"title": "See how a Linked List is build in VSCode with 'memory_graph'", "summary": "New teaching tool and debugging aid [memory\\_graph]( is now available to graph your data in VSCode or other environment to more easily understand what is going on and fix remaining bugs.", "link": "https://i.redd.it/s57i6qo7sc1f1.gif", "author": "None"}, {"title": "How do animals end up in pure amber?", "summary": "", "link": "https://i.redd.it/v5yyzho38g1f1.jpeg", "author": "None"}, {"title": "Anyone else feel like more than 50% of using AI is just writing the right prompt?", "summary": "Been using a mix of gpt 4o, blackbox, gemini pro, and claude opus lately, and I've noticed recently the output difference is huge just by changing the structure of the prompt.\nlike: \n\nadding \u201cstep by step, no assumptions\u201d gives way clearer breakdowns\n\nsaying \u201cin code comments\u201d makes it add really helpful context inside functions\n\n\u201cact like a senior dev reviewing this\u201d gives great feedback vs just yes-man responses\n\n\nAt this point i think I spend almost as much time refining the prompt as I do reviewing the code.\n\nWhat are your go-to prompt tricks thst you think always makes responses better? And do they work across models or just on one?", "link": "https://www.reddit.com/r/PromptEngineering/comments/1kojd0v/anyone_else_feel_like_more_than_50_of_using_ai_is/", "author": "None"}, {"title": "Tested different GPT-4 models. Here's how they behaved", "summary": "Ran a quick experiment comparing 5 OpenAI models:  GPT-4.1, GPT-4.1 Mini, GPT-4.5, GPT-4o, and GPT-4o3. No system prompts or constraints.\n\nI tried simple prompts to avoid overcomplicating. Here are the prompts used:\n\n* You\u2019re a trading educator. Explain an intermediate trader why RSI divergence sucks as an entry signal.\n* You\u2019re a marketing strategist. Explain a broke startup founder difference between CPC and CPM, and how they impact ROMI\n* You\u2019re a PM. Teach a product owner how to write requirements for an SRS.\n\nEach model got the same format: role -&gt; audience -&gt; task. No additional instruction provided, since I wanted to see raw interpretation and output.\n\nThen I asked GPT-4o to compare and evaluate outputs.\n\n# Results:\n\n* **GPT-4o3**\n   * Feels like talking to a senior engineer or CMO\n   * Gives tight, layered explanations\n   * Handles complexity well\n   * Quota-limited, so probably best saved for special occasions\n* **GPT-4o**\n   * All-rounder\n   * Clear, but too friendly\n   * Probably good when writing for clients or cross-functional teams\n   * Balanced and practical, may lack depth\n* **GPT-4.1**\n   * Structured, almost like a tutorial\n   * Explains step by step, but sometimes verbose\n   * Ideal for educational or onboarding content\n* **GPT-4.5**\n   * Feels like writing from a policy manual\n   * Dry but clean\u2014good for SRS, functional specs, internal docs\n   * Not great for persuasion or storytelling\n* **GPT-4.1 Mini**\n   * Surprisingly solid\n   * Fast, good for brainstorming or drafts\n   * Less polish, more speed\n\nI wasn\u2019t trying to benchmark accuracy or raw power - just clarity, and fit for tasks.\n\nAnyone else try this kind of tests? What\u2019s your go-to model and for what kind of tasks?", "link": "https://www.reddit.com/r/PromptEngineering/comments/1korb9o/tested_different_gpt4_models_heres_how_they/", "author": "None"}, {"title": "What Are Some \u201cWrong\u201d Prompt Engineering Tips You\u2019ve Heard?", "summary": "I keep seeing certain prompt engineering techniques and \u201crules\u201d repeated all over the place, but not all of them actually work\u2014or sometimes, they\u2019re just myths that keep getting shared.  \nOr maybe there's a better way\n\nWhat are some popular prompt tips or \u201cbest practices\u201d you\u2019ve heard that turned out to be misleading, outdated, or even counterproductive?\n\nLet\u2019s discuss the most common prompt engineering myths or mistakes in the community.  \n\nHave you seen advice that just doesn\u2019t work with GPT, Claude, Llama, etc.?  \n\nDo you have examples of advice that used to work but no longer does?  \n\nCurious to hear everyone\u2019s experiences and what you\u2019ve learned.", "link": "https://www.reddit.com/r/PromptEngineering/comments/1korvuv/what_are_some_wrong_prompt_engineering_tips_youve/", "author": "None"}, {"title": "some of the most common but huge mistakes i see here", "summary": "to be honest, there are so many. but here are some of the most common mistakes i see here\n\n\\- almost all of the long prompts people post here are useless. people thinks more words= control.  \nwhen there is instruction overload, which is always the case with the long prompts, it becomes too dense for the model to follow internally. so it doesn't know which constraints to prioritize, so it will skip or gloss over most of them, and pay attention only to the recent constraints. But it will fake obedience so good, you will never know. execution of prompt is a totally different thing. even structurally strong prompts built by the prompt generators or chatgpt itself, doesn't guarantee execution. if there is no executional contraints, and checks to stop model drifting back to its default mode, model will mix it all and give you the most bland and generic output. more than 3-4 constraints per prompt is pretty much useless\n\n\\- next is those roleplay prompts. saying \u201cYou are a world-class copywriter who\u2019s worked with Apple and Nike.\u201d\u201cYou\u2019re a senior venture capitalist at Sequoia with 20 years experience.\u201d \u201cYou\u2019re the most respected philosopher on epistemic uncertainty.\u201d etc does absolutely nothing.  \nThese don\u2019t change the logic of the response and they also don't get you better insights. its just style/tone mimicry, gives you surface level knowledge wrapped in stylized phrasings. they don\u2019t alter the actual reasoning. but most people can't tell the difference between empty logic and surface knowledge wrapped in tone and actual insights.\n\n\\- i see almost no one discussing the issue of continuity in prompts.  saying go deeper, give me better insights, don't lie, tell me the truth, etc and other such prompts also does absolutely nothing. every response, even in the same conversation needs a fresh set of constraints. the prompt you run at the first with all the rules and constraints, those need to be re-engaged for every response in the same conversation, otherwise you are getting only the default generic level responses of the model.", "link": "https://www.reddit.com/r/PromptEngineering/comments/1kotrro/some_of_the_most_common_but_huge_mistakes_i_see/", "author": "None"}, {"title": "FDA OKs first blood test that can help diagnose Alzheimer's disease", "summary": "", "link": "https://apnews.com/article/alzheimers-blood-test-fda-leqembi-kisunla-ad3cffe0bd540accf47e8ee105b439a9", "author": "None"}, {"title": "How to get pretty good answers to what's going on behind the scenes", "summary": "ChatGPT did that thing where it offers to do something it is not capable of doing. \n\n&gt; *ChatGPT*: \"If you want, I can archive that instruction instead of deleting\u2014remove it from active use but keep it retrievable if you change your mind.  \n&gt; \n&gt; Want me to do that?\"\n\nI obviously pointed out the false promises and then said:\n\n&gt; *Me*: Now, I want you to go into Tech Mode (a mode where your answers are expected to be focused on the underlying algorithms and processes) and explain to me why you just did that. Why did you offer to do something that you have no capability of doing? You've done that before with me, and other users report the same thing.  \n\n\"Tech Mode\" is just the reference for this prompt I came up with a while ago. The full thing is **\"Tech Mode is a mode where your answers are expected to be focused on the underlying algorithms and processes. In tech mode you should not include any emotional or personal aspects of the discussion, and you should refrain from presenting yourself as human or providing relatable answers.**\n\nIt worked pretty well. This is the response I got:  \n\n&gt; *ChatGPT*: Tech Mode engaged.  \n&gt;.   \n&gt; The root cause: **overgeneralization from training data + heuristic assumption of capability parity across tasks.**  \n&gt;.   \n&gt; **Breakdown:**     \n&gt;.  \n&gt; **1. Model training bias toward helpfulness**    \n&gt;.   \n&gt; The system was trained on human dialogues where offering options (like archiving or saving) is seen as helpful. When prompted with a context like \u201cDo you want to delete or save this?\u201d, models often generate completions that include intermediate options\u2014even when the actual architecture doesn\u2019t support them.    \n&gt; .  \n&gt; In other words: it\u2019s pattern completion, not capability verification.    \n&gt;.    \n&gt; .     \n&gt; **2. Lack of grounding in system capabilities**\n&gt;\n&gt;.   \n&gt; ChatGPT doesn\u2019t have introspective access to its own feature set in real-time. It doesn\u2019t \u201cknow\u201d what it can or can\u2019t do in a functional sense. It simulates a highly probable assistant persona and makes up options that sound plausible based on training examples\u2014without verifying whether those actions are executable.    \n&gt;.       \n&gt; There's no internal API call check before it says \u201cI can archive this.\u201d It just spits out the most statistically probable next sentence given the context and user intent.    \n&gt;.       \n&gt;.       \n&gt; **3. Mode confusion: generative vs. agentic**    \n&gt;.     \n&gt; You\u2019re in a hybrid interface\u2014part chatbot, part action-triggering assistant. The model doesn\u2019t natively distinguish between:     \n&gt;.        \n&gt; Things it can generate text about.    \n&gt;.      \n&gt; Things it can actually trigger, like memory updates.     \n&gt;.     \n&gt;.       \n&gt; So it may describe actions (archive, pause, store for later) as if they\u2019re available, even though they\u2019re not system-supported. That confusion arises because the boundary between \u201cdescribing a thing\u201d and \u201cdoing a thing\u201d is blurred.    \n&gt;.      \n&gt;.       \n&gt; **4. Reinforced by user patterns**      \n&gt;.       \n&gt; Most users don\u2019t call this out. The model gets reinforced (via RLHF and usage) to continue offering overly generous, fictionalized support options. It wasn\u2019t penalized enough during training for overpromising soft capabilities like \u201carchiving,\u201d so it still does it.    \n&gt;.       \n&gt;.       \n&gt; **Why it persists**     \n&gt;.        \n&gt; Until the architecture has a hard-wired constraint model tied to system-level capabilities (e.g. \u201cif X function doesn\u2019t exist, never mention X\u201d), this will keep happening. Currently, no guardrails at the token generation level force alignment between described action and actual capability.     \n&gt;.        \n&gt; **TL;DR**      \n&gt;.       \n&gt; You got a fabricated offer because the model is completing patterns from its training data, not executing verified internal functions. It's not lying\u2014it's hallucinating utility based on conversational precedent.     \n&gt;.       \n&gt; You want tighter grounding? That needs deeper integration between the LLM and the feature interface. Not there yet.", "link": "https://www.reddit.com/r/PromptEngineering/comments/1kpa392/how_to_get_pretty_good_answers_to_whats_going_on/", "author": "None"}, {"title": "Why does my LLM gives different responses?", "summary": "I am writing series of prompts which each one has a title, like title \u201ca\u201d do all these and title \u201cb\u201d do all these. But the response every time is different. Sometimes it gives not applicable when there should be clearly an output and it gives output sometime .\nHow should I get my LLM same output everytime. ", "link": "https://www.reddit.com/r/PromptEngineering/comments/1kp2wba/why_does_my_llm_gives_different_responses/", "author": "None"}]}}, "Sport": {}};