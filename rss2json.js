const rss2json = {"Scitech": {"https://newatlas.com/science/index.rss": {"feed": {"title": "Science"}, "entries": [{"title": "Nissan's new paint cools cars by up to 21 \u00b0F in direct sunlight", "summary": "Nissan has demonstrated a new automotive paint that can drastically cool a vehicle parked in direct sunshine. Tests have shown that treated cars stay up to 21.6 \u00b0F (12 \u00b0C) cooler than untreated cars parked side by side.Category: Coating, Coatings, Cooling, Paint, Vehicle, Automotive, Nissan,...", "link": "https://newatlas.com/materials/nissans-passive-cooling-coating-cars/", "published_js": "2024-08-08", "author": "Michael Irving"}]}, "https://www.cbsnews.com/latest/rss/science": {"feed": {"title": "Science - CBSNews.com"}, "entries": [{"title": "NASA readies backup plan if Starliner crew landing ruled out", "summary": "No final decisions have been made and NASA remains hopeful ongoing tests will show the Starliner can safely return its crew to Earth.", "link": "https://www.cbsnews.com/news/starliner-iss-nasa-crew-stuck-backup-plan/", "published_js": "2024-08-07", "author": "None"}]}, "https://www.cbsnews.com/latest/rss/space": {"feed": {"title": "Space - CBSNews.com"}, "entries": [{"title": "Disagreement over plans to return Starliner astronauts amid safety concerns", "summary": "NASA launched Boeing's Starliner two months ago on a one-week mission. However, the two astronauts are still aboard the International Space Station and NASA says officials can't agree if Starliner is safe to bring them home. A new plan could keep them there until February.", "link": "https://www.cbsnews.com/video/disagreement-over-plans-to-return-starliner-astronauts-amid-safety-concerns/", "published_js": "2024-08-08", "author": "None"}]}}, "Gadgets": {"https://www.emergentmind.com/feeds/rss": {"feed": {"title": "Emergent Mind Feed"}, "entries": [{"title": "Achieving Human Level Competitive Robot Table Tennis", "summary": "Abstract:\n\"Achieving human-level speed and performance on real world tasks is a north star for the  and (ii) a high level  to defining the task distribution that is grounded in the real-world and defines an automatic curriculum, and (3) real time adaptation to unseen...", "link": "https://www.emergentmind.com/papers/2408.03906?utm_campaign=paper&utm_content=papers&utm_medium=rss", "published_js": "2024-08-07", "author": "None"}, {"title": "CodexGraph: Bridging Large Language Models and Code Repositories via Code Graph Databases", "summary": "Abstract:\n\" (LLMs) excel in stand-alone code tasks like  or manual tools and . To mitigate these limitations, we introduce \\framework, a system that integrates  with  interfaces extracted from code repositories. By leveraging the structural properties of graph  and code navigation. We...", "link": "https://www.emergentmind.com/papers/2408.03910?utm_campaign=paper&utm_content=papers&utm_medium=rss", "published_js": "2024-08-07", "author": "None"}, {"title": "Compact 3D Gaussian Splatting for Static and Dynamic Radiance Fields", "summary": "Abstract:\n\" (-based representation and introduces an approximated  and promising . Furthermore, subsequent studies have successfully extended 3DGS to  scenes, demonstrating its wide range of applications. However, a significant drawback arises as 3DGS and its following methods entail a substantial number of Gaussians to...", "link": "https://www.emergentmind.com/papers/2408.03822?utm_campaign=paper&utm_content=papers&utm_medium=rss", "published_js": "2024-08-07", "author": "None"}]}}, "Food_Health": {"https://phys.org/rss-feed/biology-news/agriculture/": {"feed": {"title": "Agriculture news"}, "entries": [{"title": "Unlocking the secrets of salt stress tolerance in wild tomatoes", "summary": "As our climate changes and soil salinity increases in many agricultural areas, finding crops that can thrive in these challenging conditions is crucial. Cultivated tomatoes, while delicious, often struggle in salty soils. Their wild cousins, however, have evolved to survive in diverse and often harsh...", "link": "https://phys.org/news/2024-08-secrets-salt-stress-tolerance-wild.html", "published_js": "2024-08-08", "author": "None"}, {"title": "Research findings suggest nilgai antelope are not carriers of bovine babesiosis", "summary": "Nilgai, a non-native antelope species that freely ranges Southern Texas and Northeastern Mexico, do not appear to be susceptible to infection following experimental exposure to Babesia bovis, according to recent findings by Texas A&amp;M AgriLife Research scientists.", "link": "https://phys.org/news/2024-08-nilgai-antelope-carriers-bovine-babesiosis.html", "published_js": "2024-08-08", "author": "None"}, {"title": "High nitrogen input promotes the redistribution of new organic carbon to deeper soil layers", "summary": "Exogenous reactive nitrogen input has a profound effect on the carbon cycle of terrestrial ecosystems. Most current research on soil organic carbon (SOC) dynamics in relation to nitrogen input has focused predominantly on the surface soil layers. However, studies limited to the surface layer cannot...", "link": "https://phys.org/news/2024-08-high-nitrogen-redistribution-carbon-deeper.html", "published_js": "2024-08-08", "author": "None"}, {"title": "Proteomic insights reveal key strategies to extend broccoli's freshness and shelf life", "summary": "A research team has investigated proteome-level changes in harvested broccoli florets stored at room temperature and refrigerated conditions using Tandem Mass Tag (TMT) technology. Their findings reveal that cold storage temperatures reduce protein degradation pathways and key metabolic activities, including autophagy and carbon metabolism.", "link": "https://phys.org/news/2024-08-proteomic-insights-reveal-key-strategies.html", "published_js": "2024-08-08", "author": "None"}, {"title": "Disaster plant pathology: Solutions to combat agricultural threats from disasters", "summary": "An often-overlooked component of natural and human-driven disasters is their potential to affect plant health and thus food security at domestic and international scales. Most disasters have indirect effects on plant health through factors such as disruptions to supply chains and damaged infrastructure, but there...", "link": "https://phys.org/news/2024-08-disaster-pathology-solutions-combat-agricultural.html", "published_js": "2024-08-07", "author": "None"}, {"title": "How media impacts digital technology adoption in US and Brazilian agriculture", "summary": "Digital technologies on the farm improve efficiency, productivity, and profits, but few farmers are taking full advantage of available tools. According to University of Illinois Urbana-Champaign researchers, communication channels play an important role in farmers' decision-making process around technology adoption.", "link": "https://phys.org/news/2024-08-media-impacts-digital-technology-brazilian.html", "published_js": "2024-08-07", "author": "None"}, {"title": "Pixels to pasture: How AI can help farmers predict their pasture", "summary": "Researchers from the Alliance of Bioversity International and CIAT have paved the way for farmers (from small-holders to big ranchers) information about the quantity and quality of their grazing pastures, right there on their smartphone.", "link": "https://phys.org/news/2024-08-pixels-pasture-ai-farmers.html", "published_js": "2024-08-07", "author": "None"}, {"title": "Sward diversification more effective for higher yields than some microbial fertilizers", "summary": "A new scientific paper from Teagasc, UCC and international collaborators has shown diversification of the plant species in swards can be more effective than the application of microbial inoculants in supporting productivity in intensively managed grasslands.", "link": "https://phys.org/news/2024-08-sward-diversification-effective-higher-yields.html", "published_js": "2024-08-07", "author": "None"}, {"title": "Teosinte Pollen Drive: Scientists may have discovered corn's 'missing link'", "summary": "Cold Spring Harbor Laboratory (CSHL) has begun to unravel a mystery millennia in the making. Our story begins 9,000 years ago. It was then that maize was first domesticated in the Mexican lowlands. Some 5,000 years later, the crop crossed with a species from the...", "link": "https://phys.org/news/2024-08-teosinte-pollen-scientists-corn-link.html", "published_js": "2024-08-07", "author": "None"}]}}, "Nature": {"http://feeds.feedburner.com/DiscoverLivingWorld": {"feed": {"title": "Planet Earth | Discover Magazine"}, "entries": []}, "http://feeds.feedburner.com/DiscoverEnvironment": {"feed": {"title": "Environment | Discover Magazine"}, "entries": [{"title": "Atlantic Ocean Conveyor Likely to Collapse Before 2050, Say Climate Scientists", "summary": "Climate change is about to cause the collapse of one of the world's great ocean currents. The consequences will be devastating", "link": "https://www.discovermagazine.com/environment/atlantic-ocean-conveyor-likely-to-collapse-before-2050-say-climate", "published_js": "2024-08-07", "author": "The Physics arXiv Blog"}]}}, "Business": {}, "Foss_Self-hosting": {}, "History": {}, "News": {"https://www.livemint.com/rss/elections": {"feed": {"title": "mint - elections"}, "entries": []}, "swarajyamag.com": {"feed": {"title": "swarajyamag.com"}, "entries": [{"title": "RBI Raises Limit For Tax Payments Through UPI To Rs 5 Lakh Per Transaction: All You Need To Know", "summary": "<a href=\" target=\"_blank\">RBI Raises Limit For Tax Payments Through UPI To Rs 5 Lakh Per Transaction: All You Need To Know</a>&nbsp;&nbsp;<font color=\"#6f6f6f\">", "link": "https://news.google.com/rss/articles/CBMiygFBVV95cUxNc0xCRFluQWZuYjRkajhmRzhORVd4eWI1OGpCYTA1T1c3TW5JTnRraFpXSUtsVjhMV3d3a091RXJGLWZzYlY3ajJqcjZZMVZwM05UM29mWUhpN2xsYlZDd1JaeEdITXhtOFliWDVtVXVMajNaZENTd19KX1RIdzhPdjUxTnNNWm5tWUhpa3JUVUJNd3VVV1p0aldKbUpyakd5aG5CbHN4STJuQ21lSnd0T0dQZ1V6NUNvWHA5VkFkQnlJaV9qdXk3b0ZB?oc=5", "published_js": "2024-08-08", "author": "None"}]}}, "Reddit": {"https://oauth.reddit.com/r/todayilearned/top": {"feed": {"title": "Reddit - TIL"}, "entries": [{"title": "TIL that the current world record holder for men's marathon died at age 24.", "summary": "", "link": "https://en.wikipedia.org/wiki/Kelvin_Kiptum", "author": "None"}, {"title": "TIL 18th Century Norwegian swashbuckler Peter Tordenskjold once ran out of ammo during a sea battle so he sent his enemy a letter thanking him for \"a fine duel\" and asking him to send more ammo so they could carry on. The two crews then toasted each other's health and went their separate ways.", "summary": "", "link": "https://en.wikipedia.org/wiki/Peter_Tordenskjold#Court-martial", "author": "None"}, {"title": "TIL that the Christian portrayal of the fruit that Eve ate as an apple may come down to a Latin pun. Eve ate a \u201cm\u0101lum\u201d (apple) and also took in \u201cmalum\u201d (evil). There\u2019s no Biblical evidence that the fruit was an apple.", "summary": "", "link": "https://en.wikipedia.org/wiki/Tree_of_the_knowledge_of_good_and_evil", "author": "None"}, {"title": "TIL that the \u201cninja killer\u201d Temujin Kensu supposedly shot someone 400 miles away by scheduling a private plane at 2 am, flying to the murder scene, then flying back leaving no trace ", "summary": "", "link": "https://www.michigandaily.com/statement/why-is-it-so-essential-that-i-die-in-here-what-i-learned-visiting-ninja-killer-temujin-kensu-in-prison-hes-innocent/", "author": "None"}, {"title": "TIL The Golden Poison Frog found in the Amazon rain forest, is the most poisonous animal on the planet.They are so toxic that they have few (if any) predators. The indigenous tribes use the toxin for hunting. Secretions from a single frog could kill two bull elephants. ", "summary": "", "link": "https://en.wikipedia.org/wiki/Golden_poison_frog#:~:text=The%20golden%20poison%20frog%20has,animal%20species%20on%20the%20planet.", "author": "None"}, {"title": "TIL that the bowler hat is the most popular headgears being worn by cowboys and outlaws alike in the Wild West, and it wasn't until the 1920s that the ten gallon hat was popularised by Hollywood. ", "summary": "", "link": "https://www.hatterist.com/blog/blog-post-title-cowboy-hat-history", "author": "None"}, {"title": "TIL In a 2022 survey by FlexJobs, 45% of remote workers reported saving at least $5,000 annually and one in 5 remote workers estimated saving $10,000 a year.", "summary": "", "link": "https://www.usatoday.com/story/money/2023/10/16/americans-save-money-by-working-from-home/71140252007/", "author": "None"}, {"title": "TIL the dark-grey color we see when we close our eyes isn't black, but Eigengrau (intrinsic grey)", "summary": "", "link": "https://en.wikipedia.org/wiki/Eigengrau#Cause", "author": "None"}, {"title": "TIL Before Washington, DC became the capital of the US, George Washington and John Adams lived in the President's House in Philadelphia during their presidencies. Due to confusion over its location, it was accidentally demolished in 1951. A public toilet was built over the site it once stood.", "summary": "", "link": "https://en.wikipedia.org/wiki/President%27s_House_(Philadelphia)", "author": "None"}, {"title": "TIL: The Trojan Ballistics Suit of Armor was a planned exoskeleton suit inspired by the MJOLNIR armor from the Halo series for Canadian soldiers featured on the Discovery Channel. Features included wrist sheaths and in suit morphine injections. The inventor died in a car crash before he finished it.", "summary": "", "link": "https://en.wikipedia.org/wiki/Trojan_Ballistics_Suit_of_Armor", "author": "None"}, {"title": "TIL about Mal de Debarquement Syndrome (disembarkment syndrome), a neurological condition usually occurring after a cruise, flight, or other sustained motion event. It is typically diagnosed when a person reports a persistent rocking, swaying, or bobbing feeling while stationary.", "summary": "", "link": "https://en.wikipedia.org/wiki/Mal_de_debarquement", "author": "None"}, {"title": "Today I learned that the comedy folk band 'The Lancashire Hotpots' were forced to change the title of their song \"The Beer Olympics\" due to copyright claims by the IOC. They then renamed the song \"The Beer International Non-Profit, Non-Governmental Sporting Quad Yearly Event.\"", "summary": "", "link": "https://en.wikipedia.org/wiki/The_Lancashire_Hotpots#Olympic_controversy", "author": "None"}, {"title": "TIL Hatshepsut, who depicted herself as a male pharaoh to establish herself in the Egyptian patriarchy, was one of the most prolific builders and oversaw a period of great prosperity and peace during her 20 years of reign", "summary": "", "link": "https://en.wikipedia.org/wiki/Hatshepsut#Reign", "author": "None"}, {"title": "TIL LeBron James has never scored 0 points in an NBA game, his fewest points in a game was against the Rockets on December 29, 2004, with 3 points", "summary": "", "link": "https://www.statmuse.com/nba/ask/lowest-scoring-games-by-the-lebron-james", "author": "None"}, {"title": "TIL that there are roughly 107 classes of animals of which we are only taught a simplified 6 in school (birds, mammals, reptiles, etc.)", "summary": "", "link": "https://en.wikipedia.org/wiki/List_of_animal_classes", "author": "None"}, {"title": "TIL that in 2018, after a tanker truck fire shut down a freeway in Los Angeles, a taco truck opened up on the freeway", "summary": "", "link": "https://www.latimes.com/local/lanow/la-me-ln-food-truck-freeway-20180824-story.html", "author": "None"}, {"title": "TIL The pedestal of the Statue of Liberty is taller than the Statue itself. Standing at 154 feet tall over the Statue's 151 feet.", "summary": "", "link": "https://bensguide.gpo.gov/j-statue-of-liberty#:~:text=The%20Statue%20of%20Liberty%20is%20151%20feet%20tall%20and%20stands,by%20an%20internal%20iron%20framework", "author": "None"}, {"title": "TIL One of the first dramatic TV shows was 'The Television Ghost' which started airing in 1931 on an experimental television network. The presenter dressed up as as a ghost and told stories of murder victims. No recordings exist of it and it's considered lost media.", "summary": "", "link": "https://en.wikipedia.org/wiki/The_Television_Ghost", "author": "None"}, {"title": "TIL in 1845 a suspension bridge crowded with children collapsed under their weight killing 79. They had gathered to watch a clown in a barrel being pulled by geese down the river.", "summary": "", "link": "https://www.bbc.com/news/uk-england-norfolk-24240357", "author": "None"}, {"title": "TIL about a 1980 oil drilling disaster in Louisiana that drained the state's largest freshwater lake into a salt mine", "summary": "", "link": "https://www.youtube.com/watch?v=4geh_h8Qfk8", "author": "None"}, {"title": "TIL that during the 70s and 80s, dozens of fires were set off deliberately in Hoboken, which displaced thousands of mostly Hispanic residents and killed 56. Investigators suspected that they were started by landlords in arson for profit schemes in order to sell newly renovated apartments to yuppies.", "summary": "", "link": "https://www.hobokenmuseum.org/the-hoboken-fires-a-timeline/", "author": "None"}, {"title": "TIL that Uranium is the heaviest element in nature.", "summary": "", "link": "https://en.wikipedia.org/wiki/Uranium", "author": "None"}, {"title": "TIL that a sonic boom doesnt occur only after an object breaks the sound barrier, but is produced continously as the object travels at supersonic speeds", "summary": "", "link": "https://en.wikipedia.org/wiki/Sonic_boom", "author": "None"}, {"title": "TIL the 1900 Summer Olympics had mail coach driving as an equestrian event. The contestants drove mail coaches drawn by four horses each, with the winners determined by a jury.", "summary": "", "link": "https://en.wikipedia.org/wiki/Equestrian_at_the_1900_Summer_Olympics_%E2%80%93_Mail_coach", "author": "None"}]}, "https://oauth.reddit.com/.json": {"feed": {"title": "Reddit - TIL"}, "entries": [{"title": "India\u2019s Uncertain Future in Bangladesh", "summary": "", "link": "https://foreignpolicy.com/2024/08/06/bangladesh-hasina-protests-resignation-modi-india-china/", "author": "None"}, {"title": "Tool to check if improvements in automated metrics are meaningful (p-value is not enough!)", "summary": "", "link": "https://youtu.be/itZ96W5KVcI", "author": "None"}, {"title": "AI researcher says that ChatGPT's \"secret ingredient\" may be holding back LLM capabilities", "summary": "1/ Andrej Karpathy, former OpenAI researcher, criticizes the effectiveness of reinforcement learning from human feedback (RLHF) in training AI language models.\r\n\r\n2/ He sees RLHF as a bottleneck and stopgap solution, since traditional reinforcement learning (RL), i.e. machine feedback based on clearly defined goals, is not yet applicable to LLMs.\r\n\r\n3/ With RLHF, human reviewers are asked about their preferences and trained on a \"reward model\" that is just a \"vibe check\" and not a real goal, Karpathy argues. He compares RLHF to the training of Deepmind's AlphaGo, which was trained with \"real RL.\n\n", "link": "https://www.reddit.com/r/TheDecoder/comments/1en43sc/ai_researcher_says_that_chatgpts_secret/", "author": "None"}, {"title": "Chipmakers prepare for the angstrom age with successful tests of next-gen lithography machines", "summary": "\ud83d\udc49 Imec and ASML have successfully tested the next generation of chip manufacturing machines. Using the High-NA tool, they were able to print circuits as small or smaller than those currently used in commercial production in a single pass.\r\n\r\n\ud83d\udc49 High-NA EUV lithography uses higher numerical aperture light beams to create smaller and more complex circuit structures on semiconductor wafers. This enables the production of faster, more powerful and more energy-efficient chips.\r\n\r\n\ud83d\udc49 Chipmakers such as Intel, TSMC, Samsung Electronics, SK Hynix and Micron have already ordered or purchased High-NA systems. The technology is seen as critical to the further miniaturization of logic and memory technologies and is expected to pave the way for the \"angstrom era\".\n\n", "link": "https://www.reddit.com/r/TheDecoder/comments/1en3vng/chipmakers_prepare_for_the_angstrom_age_with/", "author": "None"}, {"title": "Portrait platinum print of Balbir Singh of Faridkot State, ca.1900", "summary": "", "link": "https://i.redd.it/f3u3ywpskchd1.png", "author": "None"}, {"title": "Multi-agent system to execute a data science pipeline with just two inputs", "summary": "", "link": "https://github.com/AiFlowSolutions/MADS", "author": "None"}, {"title": "In 1835, the first assassination attempt of a US president was made on Andrew Jackson by a mentally unstable man named Richard Lawrence. Both of Lawrence's pistols misfired &amp; he was restrained with the help of Davy Crockett, (yes, that Davy Crockett) while a 68 year old Jackson beat him with a cane", "summary": "", "link": "https://i.redd.it/d0sbh0lu2ehd1.jpeg", "author": "None"}, {"title": "Fine tune Llama-2-chat", "summary": "Hi everyone, I'm working on LLMs.\n\nIn my experiment I have to fine tune Llama-2-chat and I was trying to use you library, but I have some issues to understand the format of the dataset in fine tune process.\n\nThe fine tune seems go ok, but when I ask to the fine tuned model to generate again a text, kernel crashes and gives me this error:\n\nError device-side assert triggered at line 90 in file /src/csrc/ops.cu\n\n/opt/conda/conda-bld/pytorch_1704987394225/work/aten/src/ATen/native/cuda/IndexKernel.cu:92: operator(): block: [0,0,0], thread: [0,0,0] Assertion \\-sizes\\[i\\] &lt;= index &amp;&amp; index &lt; sizes\\[i\\] &amp;&amp; \"index out of bounds\"\\ failed.\\\n\nthis is my entire code I m using, could you help me in some way?  \nmy idea is there is some issues in the format of train dataset for llama2-chat, **have you some example of dataset in the format of dataset training for llama-2-chat, or a full code** [**like this**]( **but for the case of LLAMA2-chat?**\n\nthank you so much!!!\n\n    from unsloth import FastLanguageModel\n    from unsloth.chat_templates import get_chat_template\n    \n    model, tokenizer = FastLanguageModel.from_pretrained(\n        model_name = \"unsloth/llama-2-7b-chat\",\n        max_seq_length = 512,\n        dtype = None,\n        load_in_4bit = True,\n        device_map = {\"\": 0})\n    \n    tokenizer = get_chat_template(\n        tokenizer,\n        chat_template = \"llama\")\n    \n    def formatting_prompts_func(prompts):\n        convs = prompts[\"conversations\"]\n        texts = [tokenizer.apply_chat_template(conv, tokenize = False, add_generation_prompt = False) for conv in convs]\n        return { \"text\" : texts, }\n    \n    convs= {\"conversations\" : [[{'role': 'user', 'content': 'Hi there!'},\n         {'role': 'assistant', 'content': \"HI I M CHAT\"},\n         {'role': 'user', 'content': 'What s your name?'},\n         {'role': 'assistant', 'content': \"LLAMA2\"},\n         {'role': 'user', 'content': 'how old are you?'},\n         {'role': 'assistant', 'content': 'I AM A BOT I HAVE NOT AN AGE'}]\n         # and many other like these...\n         ]}\n    \n    from datasets import Dataset\n    \n    traindf = Dataset.from_dict(convs)\n    new_dataset = traindf.map(formatting_prompts_func, batched = True)\n    \n    from unsloth import FastLanguageModel\n    import torch\n    from trl import SFTTrainer\n    from transformers import TrainingArguments\n    \n    model, tokenizer = FastLanguageModel.from_pretrained(\n        model_name = \"unsloth/llama-2-7b-chat\",\n        max_seq_length = 512,\n        dtype = None,\n        load_in_4bit = True,\n        device_map = {\"\": 0}\n    )\n    \n    \n    def generate_text(text):\n        inputs = tokenizer(text, return_tensors=\"pt\").to(\"cuda:0\")\n        outputs = model.generate(**inputs, max_new_tokens=250)\n        print(tokenizer.decode(outputs[0], skip_special_tokens=True))\n    \n    FastLanguageModel.for_inference(model)\n    \n    print(\"Before training\\n\")\n    generate_text(\"&lt;human&gt;: List the top 5 most popular movies of all time.\\n&lt;bot&gt;: \")\n    \n    print(model)\n    print(tokenizer)\n    \n    # 4. Do model patching and add fast LoRA weights and training\n    model = FastLanguageModel.get_peft_model(\n        model,\n        r = 16,\n        target_modules = [\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\",\n                          \"gate_proj\", \"up_proj\", \"down_proj\",],\n        lora_alpha = 16,\n        lora_dropout = 0, # Supports any, but = 0 is optimized\n        bias = \"none\",    # Supports any, but = \"none\" is optimized\n        use_gradient_checkpointing = True,\n        random_state = 3407,\n        max_seq_length = 512,\n        use_rslora = False,  # Rank stabilized LoRA\n        loftq_config = None, # LoftQ\n    )\n    \n    trainer = SFTTrainer(\n        model = model,\n        train_dataset = new_dataset,\n        dataset_text_field = \"text\",\n        max_seq_length = 512,\n        tokenizer = tokenizer,\n        args = TrainingArguments(\n            per_device_train_batch_size = 2,\n            gradient_accumulation_steps = 4,\n            warmup_steps = 10,\n            max_steps = 3,\n            fp16 = not torch.cuda.is_bf16_supported(),\n            bf16 = torch.cuda.is_bf16_supported(),\n            logging_steps = 1,\n            output_dir = \"outputs\",\n            optim = \"adamw_8bit\",\n            weight_decay = 0.01,\n            lr_scheduler_type = \"linear\",\n            seed = 3407,\n        ),\n    )\n    trainer.train()\n    \n    print(\"\\n ######## \\nAfter training\\n\")\n    generate_text(\"&lt;human&gt;: List the top 5 most popular movies of all time.\\n&lt;bot&gt;: \")\n    \n    \n    \n    \n    \n    from unsloth import FastLanguageModel\n    from unsloth.chat_templates import get_chat_template\n    \n    \n    model, tokenizer = FastLanguageModel.from_pretrained(\n        model_name = \"unsloth/llama-2-7b-chat\",\n        max_seq_length = 512,\n        dtype = None,\n        load_in_4bit = True,\n        device_map = {\"\": 0})\n    \n    \n    tokenizer = get_chat_template(\n        tokenizer,\n        chat_template = \"llama\")\n    \n    \n    def formatting_prompts_func(prompts):\n        convs = prompts[\"conversations\"]\n        texts = [tokenizer.apply_chat_template(conv, tokenize = False, add_generation_prompt = False) for conv in convs]\n        return { \"text\" : texts, }\n    \n    \n    convs= {\"conversations\" : [[{'role': 'user', 'content': 'Hi there!'},\n         {'role': 'assistant', 'content': \"HI I M CHAT\"},\n         {'role': 'user', 'content': 'What s your name?'},\n         {'role': 'assistant', 'content': \"LLAMA2\"},\n         {'role': 'user', 'content': 'how old are you?'},\n         {'role': 'assistant', 'content': 'I AM A BOT I HAVE NOT AN AGE'}]\n         # and many other like these...\n         ]}\n    \n    \n    from datasets import Dataset\n    \n    \n    traindf = Dataset.from_dict(convs)\n    new_dataset = traindf.map(formatting_prompts_func, batched = True)\n    \n    \n    from unsloth import FastLanguageModel\n    import torch\n    from trl import SFTTrainer\n    from transformers import TrainingArguments\n    \n    \n    model, tokenizer = FastLanguageModel.from_pretrained(\n        model_name = \"unsloth/llama-2-7b-chat\",\n        max_seq_length = 512,\n        dtype = None,\n        load_in_4bit = True,\n        device_map = {\"\": 0}\n    )\n    \n    \n    \n    def generate_text(text):\n        inputs = tokenizer(text, return_tensors=\"pt\").to(\"cuda:0\")\n        outputs = model.generate(**inputs, max_new_tokens=250)\n        print(tokenizer.decode(outputs[0], skip_special_tokens=True))\n    \n    \n    FastLanguageModel.for_inference(model)\n    \n    \n    print(\"Before training\\n\")\n    generate_text(\"&lt;human&gt;: List the top 5 most popular movies of all time.\\n&lt;bot&gt;: \")\n    \n    \n    print(model)\n    print(tokenizer)\n    \n    \n    # 4. Do model patching and add fast LoRA weights and training\n    model = FastLanguageModel.get_peft_model(\n        model,\n        r = 16,\n        target_modules = [\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\",\n                          \"gate_proj\", \"up_proj\", \"down_proj\",],\n        lora_alpha = 16,\n        lora_dropout = 0, # Supports any, but = 0 is optimized\n        bias = \"none\",    # Supports any, but = \"none\" is optimized\n        use_gradient_checkpointing = True,\n        random_state = 3407,\n        max_seq_length = 512,\n        use_rslora = False,  # Rank stabilized LoRA\n        loftq_config = None, # LoftQ\n    )\n    \n    \n    trainer = SFTTrainer(\n        model = model,\n        train_dataset = new_dataset,\n        dataset_text_field = \"text\",\n        max_seq_length = 512,\n        tokenizer = tokenizer,\n        args = TrainingArguments(\n            per_device_train_batch_size = 2,\n            gradient_accumulation_steps = 4,\n            warmup_steps = 10,\n            max_steps = 3,\n            fp16 = not torch.cuda.is_bf16_supported(),\n            bf16 = torch.cuda.is_bf16_supported(),\n            logging_steps = 1,\n            output_dir = \"outputs\",\n            optim = \"adamw_8bit\",\n            weight_decay = 0.01,\n            lr_scheduler_type = \"linear\",\n            seed = 3407,\n        ),\n    )\n    trainer.train()\n    \n    \n    print(\"\\n ######## \\nAfter training\\n\")\n    generate_text(\"&lt;human&gt;: List the top 5 most popular movies of all time.\\n&lt;bot&gt;: \")", "link": "https://www.reddit.com/r/unsloth/comments/1en4lvc/fine_tune_llama2chat/", "author": "None"}, {"title": "Fine tuning static embeddings (fasttext)", "summary": "Maybe a dumb question, but is it possible to fine tune models like fasttext? Therefore, to use prettained model and fine-tune it on my data to get better embedding representations? \nThank you", "link": "https://www.reddit.com/r/LanguageTechnology/comments/1en19qx/fine_tuning_static_embeddings_fasttext/", "author": "None"}, {"title": "India to get its latest Earth observation satellite on Independence day", "summary": "", "link": "https://www.firstpost.com/world/india-to-get-its-latest-earth-observation-satellite-on-independence-day-13802111.html", "author": "None"}, {"title": "\"36 Executed in Last 24 hours\" - Mass Executions Underway as Islamic Republic Escalates Its Killing Spree", "summary": "", "link": "https://iranhumanrights.org/2024/08/mass-executions-underway-as-islamic-republic-escalates-its-killing-spree/", "author": "None"}, {"title": "What's wrong with JUST generating text?", "summary": "", "link": "https://johnsball.substack.com/p/whats-wrong-with-just-generating", "author": "None"}, {"title": "Question regarding Bangladesh army reaction to protests?\n", "summary": "During the protest the army only deployed:\u00a0[BTR 80](\u00a0[MT LB](\u00a0[Pindad Anoa](\u00a0[BOV M11](\u00a0[RN-94](\u00a0and the\u00a0[Type 85 AFV](\n\nWhy did it not deploy the tanks (Based on Images I can find no deployment of the\u00a0[MBT-2000](\u00a0[Type 59 Durjoy](\u00a0[Type 69-IIG](\u00a0or the\u00a0[VT-5](\n\nWhy were only regular units initially deployed in place of the well known at least by foreign news terms BGB or Ansars?\n\nWhy were no orders also issued to aerial units such as in Egypt during 2011?\n\nAlso why did the army refuse do fire upon the protestors I was under the belief that BAL had entrenched itself in the army with people such as\u00a0**Aziz Ahmed**.\n\nAs someone who was always wary of the Military, Hassina failed to oversee proper deployment of forces and further aggravated the issues by making comments in place of calling for national unity and position herself against the quota system.", "link": "https://www.reddit.com/r/GeopoliticsIndia/comments/1emfohd/question_regarding_bangladesh_army_reaction_to/", "author": "None"}, {"title": "Cahokia was a pre-Columbian Indigenous city located in present-day Illinois, near St. Louis, Missouri. ", "summary": "", "link": "https://i.redd.it/vdz5nsq5ubhd1.jpeg", "author": "None"}, {"title": "Need Innovative Ideas for My CV Roasting Project\n", "summary": "I recently created a simple [project]( that roasts resumes using just prompt engineering. My professor happened to get a hold of it and now he wants me to continue developing it as an innovative project/startup.\n\nI'm a bit stuck on how to move forward. He mentioned incorporating technologies like knowledge graphs, Retrieval-Augmented Generation (RAG), and other advanced AI buzzwords. Honestly, this project doesn't even seem to need such complex tech. But, if I were to use these technologies or similar new AI advancements, how could I make something truly innovative which solves a real world problem?\n\nI know it sounds a bit dumb, but how can I bring something new and exciting to this concept app using these advanced techs or any other cutting-edge AI tech?\n\nAny ideas or suggestions would be greatly appreciated!\n", "link": "https://www.reddit.com/r/LanguageTechnology/comments/1emudva/need_innovative_ideas_for_my_cv_roasting_project/", "author": "None"}, {"title": "MiniCPM : LLM for mobiles", "summary": "", "link": "/r/ArtificialInteligence/comments/1emu9gb/minicpm_llm_for_mobiles/", "author": "None"}, {"title": "react-waves: \ud83c\udf0a Animated wave component with React", "summary": "", "link": "https://github.com/ddoemonn/react-waves", "author": "None"}, {"title": "Real-time, Free Dictation App Using Whisper and Groq with Post-Processing", "summary": "", "link": "https://github.com/aviaryan/voice-writing-electron", "author": "None"}, {"title": "Reddit Sentiment Analysis Using Hugging Face Transformers and PRAW", "summary": "[\n\n  \nMade a sentiment analyzer for reddit comments, check it out :)", "link": "https://www.reddit.com/r/LanguageTechnology/comments/1emuvg2/reddit_sentiment_analysis_using_hugging_face/", "author": "None"}, {"title": "Ukraine\u2019s incursion into Russia\u2019s Kursk region continues into second day", "summary": "", "link": "https://www.theguardian.com/world/article/2024/aug/07/ukraine-incursion-into-russia-kursk-region-continues-into-second-day", "author": "None"}, {"title": "Embedding model for PDF page retrieval [link in comments] ", "summary": "With ZeroX that launched a month ago and grew to 1.2K stars, it's clear that using multimodal LLMs to parse documents as images is the new way to go. We were trying to add a pipeline like this to our service but were quite challenged by the most important step: retrieval. MiniCPM-Llama3-V-2\\_5 can answer about 95% of questions correctly based on a document page, but it needs to be fed the right pages first.\n\nWe attempted to parse the pages into text and run embedding models on them. While it worked, the results were suboptimal since the models often missed important context, especially in visually rich documents. So we decided to train the first embedding model that ingests not only the text but also positional information about page elements to improve its understanding of the content hierarchy on the page. It's still in alpha, and we still need to train it further, but we are looking for feedback and ideas! Have you encountered this problem? What do you think about our approach?", "link": "https://www.reddit.com/r/LanguageTechnology/comments/1emml3a/embedding_model_for_pdf_page_retrieval_link_in/", "author": "None"}, {"title": "A rioter who said he was a \u201cfool\u201d for getting involved in disorder at a mosque and punching a police officer has been jailed for three years.", "summary": "", "link": "https://www.telegraph.co.uk/news/2024/08/07/rioter-jailed-three-years-violent-disorder/", "author": "None"}, {"title": "Dictation that includes emotion?", "summary": "Currently using OpenAi's Whisper, and it's amazing!\n\nWondering if there's any speech-to-text models that include intonation or emotional cues into their text translation. Thanks!", "link": "https://www.reddit.com/r/LanguageTechnology/comments/1emokzc/dictation_that_includes_emotion/", "author": "None"}, {"title": "Massive Roman Fort Discovered in Wales Reveals Hidden History", "summary": "", "link": "https://www.dagens.com/world/massive-roman-fort-discovered-in-wales-reveals-hidden-history", "author": "None"}, {"title": "EnGuru - Groq powered RAG based English AI Tutor [lightning fast inference]", "summary": "", "link": "https://github.com/JUSTSUJAY/Enguru", "author": "None"}]}}, "Sport": {"edition.cnn.com%20sport": {"feed": {"title": "edition.cnn.com"}, "entries": [{"title": "The latest on the Paris Olympics", "summary": "<a href=\" target=\"_blank\">The latest on the Paris Olympics</a>&nbsp;&nbsp;<font color=\"#6f6f6f\">", "link": "https://news.google.com/rss/articles/CBMiiAFBVV95cUxNQWhHT3BsTkxTMWg0SXUyZE4yYmEzODI3OGx4cThoMk1Oam5oSHg5cVFYVnphT0RycVBaOWpqbFNCV25haGM2U210elF6bGowdUlJZW9xNnBXZ1NGQ3ozVUl6OXdDd2NoLUl3RjhnMDdPd2pmLXVqQUR0bUNPYVZWYVNGdTBTMFVW?oc=5", "published_js": "2024-08-08", "author": "None"}, {"title": "Tug of war, pistol dueling and other strange Olympic Games", "summary": "<a href=\" target=\"_blank\">Tug of war, pistol dueling and other strange Olympic Games</a>&nbsp;&nbsp;<font color=\"#6f6f6f\">", "link": "https://news.google.com/rss/articles/CBMirgFBVV95cUxNNkgxRk54ajBUQkFxTmNfNDRtMkNwRDJQdXB3QmktWlVyeUxQcUVZU2QyUWlyWU1Bb0Nuc2ZSVVM3QmRjRzBwRXpIZjhBZ2lFVWVvX05lZDdlQ3duaHJmYThIVjF6M3JwenlZQUJjRnd1cHdCVDh3TFk5a0FmXzYxNy1nLWF1YWJrT2ZoSEdveGhyXzdsQXVXUWNZdWN4OEZwRFJybW1ISFdaU1NPR0E?oc=5", "published_js": "2024-08-08", "author": "None"}, {"title": "Quincy Hall\u2019s incredible charge and 4 other takeaways from a dramatic night of track and field at the Olympics", "summary": "<a href=\" target=\"_blank\">Quincy Hall\u2019s incredible charge and 4 other takeaways from a dramatic night of track and field at the Olympics</a>&nbsp;&nbsp;<font color=\"#6f6f6f\">", "link": "https://news.google.com/rss/articles/CBMilAFBVV95cUxQWDRrNkxUakMxYlFiLU9SN1hqaEpzRjNKWmNBZ1NxMXJGdlhOeWpsRVpWTk9NLXpCQVRraENNN0wxSkxWN2JSYXVYQnJYeU5RRVh6SkY0Ui1HM3VHam1JVTA1NUJ6XzR3SjZuSHpDRnNSVmoxMFIxZjVnelM1NDNudlJkeUFyM2NHWS1BWTFsZkpnbUY3?oc=5", "published_js": "2024-08-07", "author": "None"}, {"title": "The Noah Lyles-NBA players beef, explained", "summary": "<a href=\" target=\"_blank\">The Noah Lyles-NBA players beef, explained</a>&nbsp;&nbsp;<font color=\"#6f6f6f\">", "link": "https://news.google.com/rss/articles/CBMimAFBVV95cUxQVjNwR09XLW8xc3Nyc1pSVV9sdHlOUnJseENZRHRfV1VaZE1vcWowbGtPQnNrb1hsMTZMSjAya2NCTTljVV81SFQxTHJwOUJHOGxHcjFjNTB0MnlqNnlCTGVxX1Y4NjNOdDFDZXBJUjcwcGIwYXY4bllKQUlBaERjUVgwVW95S3VuUzRlZzFYTkZwTjZOUkF0QQ?oc=5", "published_js": "2024-08-08", "author": "None"}, {"title": "\u2018What a special moment\u2019: US figure skating team finally receives Beijing 2022 gold medals in ceremony under the Eiffel Tower", "summary": "<a href=\" target=\"_blank\">\u2018What a special moment\u2019: US figure skating team finally receives Beijing 2022 gold medals in ceremony under the Eiffel Tower</a>&nbsp;&nbsp;<font color=\"#6f6f6f\">", "link": "https://news.google.com/rss/articles/CBMiogFBVV95cUxOUnZNRHphUS1MMm9Yem1xNDgyV1NOc3BXWU9Xa1p0ZjUxYlkyNTljbU01ZnZ3TW5Oay1VMjBReWJxaVJwQk1HUVZReV9TY05PVFNoVnY5S1ZkNTgyVTk3M2VtVlQ4ckpMMWdoeFVSSkREUHpabHNkZjVlT01SeTNvMjkwelFReVZhdEhHdFJuMDBwdW9ndkhLQVZONHE5d01od3c?oc=5", "published_js": "2024-08-07", "author": "None"}]}}};